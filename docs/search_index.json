[
["index.html", "HREP Mussel Modeling Modeling Mussel Habitat Suitability for Upper Mississippi River Restoration Projects Preface 0.1 Abstract", " HREP Mussel Modeling Modeling Mussel Habitat Suitability for Upper Mississippi River Restoration Projects Michael Dougherty, Geographer, US Army Corps of Engineers, Rock Island District Davi Michl, Biologist, US Army Corps of Engineers, Rock Island District Dan Kelner, Fisheries Biologist, US Army Corps of Engineers, St. Paul District 2019-03-07 Preface This project has been funded by the US Army Corps of Engineers (USACE) Upper Mississippi River Restoration Program (UMRR). 0.1 Abstract "],
["introduction.html", "Chapter 1 Introduction 1.1 Literature Review 1.2 Identify Available Datasets", " Chapter 1 Introduction Species Distribution Modeling (SDM) has become a common method for mapping suitable habitats for many species or taxa groups (Elith, Leathwick, and Hastie 2008, Elith and Leathwick (2009)). The dismo R package has been created to support SDM in R (see the dismo package vignette sdm, Hijmans and Elith 2013). Another good overview of SDM in R (Hijmans and Elith, n.d.). 1.1 Literature Review MCAT UMESC Pool 8 mussel model UMESC Pool 18 mussel model 1.2 Identify Available Datasets The USACE Mussel Database HREP pre-project survey 2018 Steamboat survey 2014 Cordova survey 2010 Cordova survey References "],
["mussel-data-processing.html", "Chapter 2 Mussel Data Processing 2.1 Prepare Mussel Sample Data", " Chapter 2 Mussel Data Processing 2.1 Prepare Mussel Sample Data Working geodatabase: //mvrdfs/egis/Work/EMP/HREP_Projects/SteamboatSlough/Mussels/SteamboatMusselModel/Data/SB_Mussels.gdb Import sample location point feature class for each survey. Import “individual” data tables for each survey. Add double fields ‘Easting’ and ‘Northing’ and calculate geometry for each sample location point feature class. Add double fields ‘Easting’ and ‘Northing’ to each mussel tabular data. Join the sample location point feature class to each mussel tabular data. Directionality of join is important: right-click mussel tabular data and select join, using SAMPLEID as join field. Field calculate ‘Easting’ and ‘Northing’ from the sample location point feature class. Then remove the join. Use the “Display XY” tool to create events from the mussel tabular data. Export the events to the geodatabase as: Cordova_YEAR Create 3 new fields (type: long integer) titled ‘NumberLive’, ‘NUM5YEAR’, and ‘NUM30MM’ Use field calculator to populate each field with ‘0’ indicating absence and ‘1’ for presence in each new field (number live, number less than 5 years, and number less than 30mm in length). Create a definition query to select only those records where: NUMBER_LIV &gt; 0 Dissolve the Cordova_YEAR feature class by SAMPLEID to collapse mussel tabular data to the unique sample location points. The dissolve tool can also be used to collapse mussel tabular data to unique sample location using multiple fields; e.g., if a count by species is required for analysis, select SAMPLEID and ScientificName. In the statistics box, add the newly created fields ‘Number_Live’, ‘NUM5YEAR’, and ‘NUM30MM’ and select ‘SUM’ as statistic to be calculated for each. Append all three datasets into one feature class in the .gdb called Cordova. Right-click this feature class and select ‘load’. Export to .csv. "],
["calculate-mussel-metrics.html", "Chapter 3 Calculate Mussel Metrics 3.1 Prepare Mussel Sample Metrics 3.2 MCAT Metrics 3.3 Create the Individuals table 3.4 Create Percent Listed 3.5 Create Percent Tolerant 3.6 Create Percent Tribe Lampsilini 3.7 Create Percent Juveniles 3.8 Create Percent Over 15 Years 3.9 Create Abundance 3.10 Create Species Evenness 3.11 Create Tribe Eveness 3.12 Create ES 100 3.13 Determine MCAT Metric per site threshold 3.14 Choice of Site Level MCAT Metric Thresholds 3.15 Export to Maxent “SWD” format", " Chapter 3 Calculate Mussel Metrics 3.1 Prepare Mussel Sample Metrics The purpose of this section is to calculate various metrics of habitat quality for each sampled site. Each of these metrics will be used as presence data as input to create a set of Maxent habitat suitability models. The metrics calculated in this section were taken from the Upper Mississippi River Mussel Community Assessment Tool (MCAT) (Dunn, Zigler, and Newton 2016). 3.2 MCAT Metrics The following MCAT metrics were selected for inclusion in the model: percent listed species: percent of listed threatened or endangered species (federal or bordering states) is a measure of sensitive species percent tolerant: percent of tolerant species (Amblema plicata, Quadrula quadrula, and Obliquaria reflexa) is a measure of a highly disturbed mussel assemblage; i.e., dominated by species tolerant of unstable substrates, silt accumulation, low current velocities, and fluctuating flow conditions. percent tribe Lampsilini: percent of assemblage that falls within tribe Lampsilini is a measure of species composition, life history, and behavioral characteristics percent juveniles: percent of mussels &lt;= 5 years-old is a measure of recruitment into an assemblage over the past five years percent &gt;= 15 yrs: percent of mussels &gt;= 15 years-old is a measure of age distribution in an assemblage Q75 abundance: a measure of abundance at the 75th quartile calculated as the density (no./m^2) species evenness: species evenness represents the dominance of an assemblage by a few species using Pielou’s evenness index (range 0 to 1) tribe evenness: tribe evenness represents the dominance of a particular taxonomic group using Pielou’s evenness index (range 0 to 1) ES_100: the expected number of species with a sample size of 100 estimated by rarefaction is a measure of a healthy mussel assemblage 3.3 Create the Individuals table The purpose of this step is to assemble the “individual” data for each of the surveys within the study area that will be used in the study. Working geodatabase: //mvrdfs/EGIS/Work/EMP/HREP_Projects/SteamboatSlough/Mussels/SteamboatMusselModel/Data/SB_Mussels.gdb/SB_ILStatePlaneW Create a feature class respresenting all individual mussel samples in the study area, using a definition query to include only live individuals and name it Cordova_all_individuals. Note: the Q75 abundance metric will be based on live mussel counts for each quadrat. Add the following fields (Type=long integer) to the attribute table: Listed, Tolerant, Lampsilini, Juveniles, Over_15yrs, tribe 3.4 Create Percent Listed The purpose of this step is to calculate the percent listed MCAT metric for each sampled site. Dissolve this feature class by SAMPLE_ID and ENAME (Scientific name). Add ‘SUM_NumberLive’ and ‘SUM_Listed’ fields in the Statistics section of the tool. Uncheck create multipart features. Set Output Feature Class to the working .gdb and name it PercentListed. Open the PercentListed attribute table. Add a field titled ‘Perc_listed’ Type=double and enter the expression ([SUM_Listed] / [SUM_NumberLive]) * 100 into the field calculator to calculate % of individual listed species per quadrat sample. Add 3 fields titled ‘species’ Type=string and Length=20; ‘longitude’ Type=double; and ‘latitude’ Type=double; in that order. Use field calculator to populate the field with species=“perc_listed”. Use Calculate Geometry to populate the ‘longitude’ and ‘latitude’ fields, ensuring that the coordinate system is set to ‘NAD 1983 2011 US Feet’ and ‘StatePlane Illinois West FIPS 1202’ and the units are set to US feet. Use the Symbology tab to select a suitability threshold based on quartiles (e.g., only selecting “fair” or “good” locations with &gt;=50% listed species). In the Symbology tab, Show: Quantities; field value ‘perc_listed’; classes=5; and method=quantile. Export selected to .csv for Maxent model run. 3.5 Create Percent Tolerant The purpose of this step is to calculate the percent tolerant MCAT metric for each sampled site. 3.6 Create Percent Tribe Lampsilini The purpose of this step is to calculate the percent tribe Lampsilini MCAT metric for each sampled site. 3.7 Create Percent Juveniles The purpose of this step is to calculate the percent juveniles MCAT metric for each sampled site. 3.8 Create Percent Over 15 Years The purpose of this step is to calculate the percent over 15 years old MCAT metric for each sampled site. 3.9 Create Abundance The purpose of this step is to calculate the Abundance MCAT metric for each sampled site. For the abundance metric, dissolve Cordova_all_individuals by SAMPLE_ID and ENAME (Scientific name). Add ‘SUM_NumberLive’ field in the Statistics section of the tool. Uncheck create multipart features. Set Output Feature Class to the working .gdb and name it Abundance. # Import Abundance from geodatabase abundance_sp &lt;- arc2sp(&quot;//mvrdfs/EGIS/Work/EMP/HREP_Projects/SteamboatSlough/Mussels/SteamboatMusselModel/Data/SB_Mussels.gdb/SB_ILStatePlaneW/Abundance&quot;) # Convert sp object to a data frame abundance &lt;- abundance_sp@data # Remove OBJECTID field abundance &lt;- abundance[,-1] # Convert from num. of mussels per 0.25 sq m to num. per 1.0 square m abundance$num_sq_m &lt;- abundance$SUM_NumberLive * 4 # Calculate the quantiles q &lt;- quantile(abundance$num_sq_m) q ## 0% 25% 50% 75% 100% ## 0 4 8 20 180 # Merge the abundance scores back onto the sp object sample_abundance &lt;- sp::merge(x = abundance_sp, y = abundance, by.x = &quot;SampleID&quot;, by.y = &quot;SampleID&quot;) # Export to geodatabase sp2arc(sample_abundance, fc_path = &quot;//mvrdfs/EGIS/Work/EMP/HREP_Projects/SteamboatSlough/Mussels/SteamboatMusselModel/Data/SB_Mussels.gdb/SB_ILStatePlaneW/sample_abundance&quot;) 3.10 Create Species Evenness The purpose of this step is to calculate the Pielou’s evenness index (range 0-1), estimated at the species level for each sampled site. Create a table of SampleID by species by abundance (number live). Use the Dissolve tool: Input Features: Cordova_all_individuals Output feature class: Cordova_sampleid_species Dissolve Fields: SampleID, EName Statistics Fields: NumberLive, SUM Create Multipart: unchecked Ensure that the Cordova_sampleid_species feature class is of type Point Features and not Multipoint Features. If multipoint, then use the Multipart to Singlepart tool to convert from multipoint to point feature type. # Import ArcGIS feature class into R cordova_sampleid_species &lt;- arc2sp(&quot;//mvrdfs/EGIS/Work/EMP/HREP_Projects/SteamboatSlough/Mussels/SteamboatMusselModel/Data/SB_Mussels.gdb/SB_ILStatePlaneW/Cordova_sampleid_species&quot;) # Convert sp object to a data frame sample_species &lt;- cordova_sampleid_species@data # Remove OBJECTID field sample_species &lt;- sample_species[,-1] # Convert to vegan community data matrix-like format using labdsv::matrify sample_species_matrix &lt;- labdsv::matrify(sample_species) # Calculate the Shannon-Weaver diversity index shannon_diversity &lt;- vegan::diversity(sample_species_matrix, index = &quot;shannon&quot;) # Calculate the number species per site (see ?vegan::diversity) species_number &lt;- vegan::specnumber(sample_species_matrix) # Use the following equation to calculate Pielou&#39;s evenness # See the vegan Diversity Vignette for details pielou_evenness &lt;- shannon_diversity/log(species_number) # Set NaN pielou_evenness values to zero pielou_evenness &lt;- ifelse(is.nan(pielou_evenness), 0, pielou_evenness) # Create a data frame of results pielou &lt;- data.frame(sampleid = names(pielou_evenness), shannon_diversity, species_number, pielou_evenness) # Merge the Pielou scores back onto the sp object sample_species_pielou &lt;- sp::merge(x = cordova_sampleid_species, y = pielou, by.x = &quot;SampleID&quot;, by.y = &quot;sampleid&quot;) # Export to geodatabase sp2arc(sample_species_pielou, fc_path = &quot;//mvrdfs/EGIS/Work/EMP/HREP_Projects/SteamboatSlough/Mussels/SteamboatMusselModel/Data/SB_Mussels.gdb/SB_ILStatePlaneW/sample_species_pielou&quot;) Create a table of SampleID by species Pielou evenness score. Use the Dissolve tool: Input Features: sample_species_pielou Output feature class: species_pielou Dissolve Fields: SampleID Statistics Fields: shannon_diversity, MEAN species_number, MEAN pielou_evenness, MEAN Create Multipart: unchecked Add “SWD” fields. 3.11 Create Tribe Eveness The purpose of this step is to calculate the Pielou’s evenness index (range 0-1), estimated at the tribe level. (will probably need to add a new column for tribe; dissolve on this with sample ID) In the feature class Cordova_all_individuals, create a new text variable named tribe. Use the Field Calculator tool on the tribe field to calculate its value using the following Python expression: !Ename!.split()[0] Create a table of SampleID by tribe by abundance (number live). Use the Dissolve tool: Input Features: Cordova_all_individuals Output feature class: Cordova_sampleid_tribe Dissolve Fields: SampleID, tribe Statistics Fields: NumberLive, SUM Create Multipart: unchecked # Import ArcGIS feature class into R cordova_sampleid_tribe &lt;- arc2sp(&quot;//mvrdfs/EGIS/Work/EMP/HREP_Projects/SteamboatSlough/Mussels/SteamboatMusselModel/Data/SB_Mussels.gdb/SB_ILStatePlaneW/Cordova_sampleid_tribe&quot;) # Convert sp object to a data frame sample_tribe &lt;- cordova_sampleid_tribe@data # Remove OBJECTID field sample_tribe &lt;- sample_tribe[,-1] # Convert to vegan community data matrix-like format using labdsv::matrify sample_tribe_matrix &lt;- labdsv::matrify(sample_tribe) # Calculate the Shannon-Weaver diversity index tribe_shannon_diversity &lt;- vegan::diversity(sample_tribe_matrix, index = &quot;shannon&quot;) # Calculate the number species per site (see ?vegan::diversity) tribe_number &lt;- vegan::specnumber(sample_tribe_matrix) # Use the following equation to calculate Pielou&#39;s evenness # See the vegan Diversity Vignette for details tribe_pielou_evenness &lt;- tribe_shannon_diversity/log(tribe_number) # Set NaN pielou_evenness values to zero tribe_pielou_evenness &lt;- ifelse(is.nan(tribe_pielou_evenness), 0, tribe_pielou_evenness) # Create a data frame of results tribe_pielou &lt;- data.frame(sampleid = names(tribe_pielou_evenness), tribe_shannon_diversity, tribe_number, tribe_pielou_evenness) # Merge the Pielou scores back onto the sp object sample_tribe_pielou &lt;- sp::merge(x = cordova_sampleid_tribe, y = tribe_pielou, by.x = &quot;SampleID&quot;, by.y = &quot;sampleid&quot;) # Export to geodatabase sp2arc(sample_tribe_pielou, fc_path = &quot;//mvrdfs/EGIS/Work/EMP/HREP_Projects/SteamboatSlough/Mussels/SteamboatMusselModel/Data/SB_Mussels.gdb/SB_ILStatePlaneW/sample_tribe_pielou&quot;) Create a table of SampleID by tribe Pielou evenness score. Use the Dissolve tool: Input Features: sample_tribe_pielou Output feature class: tribe_pielou Dissolve Fields: SampleID Statistics Fields: tribe_shannon_diversity, MEAN tribe_number, MEAN tribe_pielou_evenness, MEAN Create Multipart: unchecked Add “SWD” fields. 3.12 Create ES 100 The purpose of this step is to calculate the ES 100 MCAT metric for each sampled site. ES_100 is the expected number of species with a sample size of 100 estimated by rarefaction based on random resampling of the data (Dunn, Zigler, and Newton 2016). ES_100-species richness estimated by rarefaction; caveat: sites need to be compared based on an equal sample size because # of species and # of individuals sampled are large correlated. Not sure how best to approach this one; I defer to you! # Uses the sample_species_matrix calculated from the species evenness section # Calculate rarefaction using a sample size of 100 rarefy_es_100 &lt;- vegan::rarefy(x = sample_species_matrix, sample = 100) ## Warning in vegan::rarefy(x = sample_species_matrix, sample = 100): ## requested &#39;sample&#39; was larger than smallest site maximum (0) # Calculate rarefaction using a reasonable sample size rarefy_rowmedian &lt;- vegan::rarefy(x = sample_species_matrix, sample = median(rowSums(sample_species_matrix))) ## Warning in vegan::rarefy(x = sample_species_matrix, sample = ## median(rowSums(sample_species_matrix))): requested &#39;sample&#39; was larger than ## smallest site maximum (0) # Create a data frame of results rarefy_species &lt;- data.frame(sampleid = names(rarefy_es_100), rarefy_es_100, rarefy_rowmedian, shannon = diversity(sample_species_matrix), specnumber = specnumber(sample_species_matrix)) # Merge the rarefaction scores back onto the sp object rarefy_sampleid_species &lt;- sp::merge(x = cordova_sampleid_species, y = rarefy_species, by.x = &quot;SampleID&quot;, by.y = &quot;sampleid&quot;) # Export to geodatabase sp2arc(rarefy_sampleid_species, fc_path = &quot;//mvrdfs/EGIS/Work/EMP/HREP_Projects/SteamboatSlough/Mussels/SteamboatMusselModel/Data/SB_Mussels.gdb/SB_ILStatePlaneW/rarefy_sampleid_species&quot;) Create a table of SampleID by tribe Pielou evenness score. Use the Dissolve tool: Input Features: rarefy_sampleid_species Output feature class: rarefy_samples Dissolve Fields: SampleID Statistics Fields: SUM_NumberLive, MEAN rarefy_es_100, MEAN rarefy_rowmedian, MEAN shannon, MEAN specnumber, MEAN Create Multipart: unchecked Add “SWD” fields. 3.13 Determine MCAT Metric per site threshold The purpose of this section is to display the range of calculated values for each of the MCAT metrics for each of the sites in the Steamboat Island study area. The MCAT report is clear about metric thresholds to use for evaluating quality mussel beds. However, this study is using the individual site unit of analysis. Therefore, decisions must be made on what is the appropriate metric threshold to use for the site level of analysis. The descriptive statistics in this section will help to inform that decsion. 3.13.1 Percent Listed 3.13.2 Percent Tolerant 3.13.3 Percent Tribe Lampsilini 3.13.4 Percent Juveniles 3.13.5 Percent over 15 years 3.13.6 Abundance 3.13.7 Species Evenness 3.13.8 Tribe Evenness 3.13.9 ES_100 3.14 Choice of Site Level MCAT Metric Thresholds The discriptive statistics presented in the previous section were used to select MCAT metrics thresolds. Table 3.1: Translating MCAT Metric Thresholds from the Bed to the Site Scale. Bed Scale Site Scale Metrics Poor Fair Good Site Threshold No. of Sites % listed &lt;0.6 0.6-3.6 &gt;3.6 &gt;3 34 % tolerant &gt;62.7 38.3-62.7 &lt;38.3 &lt;40 72 % lampsilini &lt;17.2 or &gt;56.4 &lt;17.2-34.7 or &gt;39.5-56.4 &gt;34.7-39.5 &gt;40 93 % juveniles &lt;19.8 &lt;19.8-49.3 &gt;49.3 &gt;50 72 % &gt;= 15 years &lt;0.8 or &gt;16.0 &gt;5.6-16.0 &gt;2.4-5.6 &gt;5 13 abundance &lt;8 8-13 &gt;13 &gt;13 62 species evenness &lt;0.665 0.665-0.780 &gt;0.780 &gt;0.7 98 tribe evenness &lt;0.719 0.719-0.823 &gt;0.823 &gt;0.8 86 ES 100 &lt;11.5 11.5-15.7 &gt;15.7 3* 49 * The site threshold for this metric is lower than the bed threshold due to the lower number of individuals of each species found at each sampled site. 3.15 Export to Maxent “SWD” format References "],
["create-backgound-data.html", "Chapter 4 Create Backgound Data 4.1 Create Background Data", " Chapter 4 Create Backgound Data 4.1 Create Background Data Create a background to constrain points to aquatic areas (more data resolution) and reduce Maxent run times. Use the Create Random Points (Data Management) tool to create a background restricted to aquatic areas: Output location: \\\\mvrdfs\\EGIS\\Work\\EMP\\HREP_Projects\\SteamboatSlough\\Mussels\\SteamboatMusselModel\\Data\\SB_Mussels.gdb\\ Output feature class: background Constraining feature class:aquatic_areas_5m Number of points: 10000 Mininum allowed distance: 25m Leave all others as defaults Click Ok to run the tool Open the background attribute table. Add 3 fields titled ‘species’ Type=string and Length=20; ‘longitude’ Type=double; and ‘latitude’ Type=double; in that order. Use field calculator to populate the field with species=“background”. Use Calculate Geometry to populate the ‘longitude’ and ‘latitude’ fields, ensuring that the coordinate system is set to ‘NAD 1983 2011 US Feet’ and ‘StatePlane Illinois West FIPS 1202’ and the units are set to US feet. Do the same for unionidae_swd. Use Extract Multi Values to Points (spatial analyst) tool to write new values (velocity, depth, slope, and ss) onto feature classes unionidae_swd and background. Input point features: \\\\mvrdfs\\EGIS\\Work\\EMP\\HREP_Projects\\SteamboatSlough\\Mussels\\SteamboatMusselModel\\Data\\SB_Mussels.gdb\\background Input rasters: velocity, depth, slope, and ss (use rasters in the Adh.gdb, not .bil) copy unionidae_swd and delete 3 variable fields. Ensure all layers have same spatial reference before running the tool. Copy .gdb on local drive prior to running Maxent. Ensure all layers have same spatial reference before running the tool. May have to run Project (Data Mgmt) tool on the unionidae_swd points feature class prior to running Multi Values to Points tool. Export background and each mussel metric as .csv files. Ensure ObjectID field is deleted in Excel prior to upload in Maxent. "],
["prepare-environmental-predictor-data.html", "Chapter 5 Prepare Environmental Predictor Data 5.1 Create Mask 5.2 Set Environments 5.3 Process ADH Model Outputs 5.4 Convert to .bil format 5.5 Calculate Slope", " Chapter 5 Prepare Environmental Predictor Data 5.1 Create Mask The goal of this step is to define no data areas outside of the study. Create a new polygon feature class named: \\\\mvrdfs\\EGIS\\Work\\EMP\\HREP_Projects\\SteamboatSlough\\Mussels\\SteamboatMusselModel\\Data\\SB_Mussels.gdb\\SB_ILStatePlaneW\\study_area. Edit the the ‘study_area’ feature class by tracing one of the rasters created in the previous step (e.g., ‘velocity’). The resulting polygon will become the clip feature for the next tool run. Use the Aquatic_Areas_2010 layer to prepare data for the Clip (Analysis) tool (\\\\mvrdfs\\egis\\Data\\Layers\\Biology\\Aquatic_Areas_2010.lyr). Input Features: Aquatic Areas 2010\\Classifications\\Aquatic Areas: Level 2 Clip Features: study_area Output Feature Class: \\\\mvrdfs\\EGIS\\Work\\EMP\\HREP_Projects\\SteamboatSlough\\Mussels\\SteamboatMusselModel\\Data\\SB_Mussels.gdb\\aquatic_areas Delete “Isolated Floodplain Lake” records from the aquatic_areas attribute table. Use the Dissolve (Data Management tool) aquatic_areas using ‘LAND_WATER’ as the dissolve field. Output feature class: \\\\mvrdfs\\EGIS\\Work\\EMP\\HREP_Projects\\SteamboatSlough\\Mussels\\SteamboatMusselModel\\Data\\SB_Mussels.gdb\\aquatic_areas_dissolve Create multipart features: uncheck box Open an edit session to edit the aquatic_areas_dissolve attribute table. Select the row where ‘LAND_WATER’ field is set to Land, and delete. Run the Multipart to Singlepart Tool (Data Management) on aquatic_areas_dissolve. Name the feature class aquatic_areas_dissolve_singlepart. Turn on topobathy and use it as a guide to edit out areas where where it is too shallow in the aquatic_areas_dissolve_singlepart feature class. Be sure to merge the polygons before saving edits and delete intermediates aquatic_areas_dissolve and aquatic_areas_dissolve_singlepart. Use the Buffer (Analysis) tool to expand the study area beyond the extent of valid values. This expanded area will be used to define no data portions of the modeled Adh values. Input features: aquatic_areas Output Feature Class: \\\\mvrdfs\\egis\\Work\\EMP\\HREP_Projects\\SteamboatSlough\\Mussels\\SteamboatMusselModel\\Data\\SB_Mussels.gdb\\SB_ILStatePlaneW\\aquatic_areas_20m Distance: 20 meters Use the Polygon to Raster (Conversion) tool to convert the aquatic_areas_20m feature class to a raster. Input Features: aquatic_areas_20m Value field: OBJECTID Output Raster Dataset: \\\\mvrdfs\\egis\\Work\\EMP\\HREP_Projects\\SteamboatSlough\\Mussels\\SteamboatMusselModel\\Adh\\Existing_condition\\existingcondition.gdb\\mask Set Environments Ouput Coordinates: NAD_1983_2011_StatePlane_Illinois_West_FIPS_1202_Ft_US Processing Extent: study_area Cell Size: 3 ft 5.2 Set Environments The purpose of this step is to set the Environments to mask so that all the subsequent Adh raster outputs will have the same coordinate system, extent, cell alignment, cell size, and no data area. *Set Environments * Ouput Coordinates: `mask` * Processing Extent: `mask` * Snap raster: `mask` * Cell Size: `mask` * Mask: `mask` 5.3 Process ADH Model Outputs The goal of this step is to convert the raw Adaptive Hydraulics Model (Adh) data (depth, slope velocity, sheer stress, froude_number, reynolds_number) into raster format that can be input to the Maxent model. Adh models will be produced for the Q5 (high flow) and Q95 (low flow) flow conditions. This wil result in the creation of 12 raster (one for each of 6 Adh parameter) by 2 flow conditions. Create a new folder and geodatabase to represent the alternative that this Adh model represents. In this example we will be modeling the existing condition alternative: \\\\mvrdfs\\egis\\Work\\EMP\\HREP_Projects\\SteamboatSlough\\Mussels\\SteamboatMusselModel\\Adh\\Existing_condition/existingcondition.gdb Get the Adh output from the hydraulic engineer. Copy it to the alternative folder you created in the last step. EC-HH Working directory: \\\\mvr-netapp2\\MVRDATA\\ED\\ec-hh\\Mississippi_River\\Steamboat Island\\AdH\\Model Runs\\ Use Excel to convert the space-delimited .txt file to .csv. Open a blank Excel workbook and open the .txt file. Use the import wizard to convert the space-delimited file into an Excel workbook. Ensure the import works correctly, delete any header information above the row of field names, and then save as a .csv file. Import the .csv file into the existingcondition geodatabase. Name the table by the flow condition it represents (Q5, Q95). Add the Q5 table into a blank ArcMap document. Right-click the Q5 table and click “Display XY Data”. Set appropriate ‘X’,‘Y’, and ‘Z’ fields. Identify the datum and coordinate system recorded in the Adh table; all future output feature classes and rasters will need to be in the same projected coordinate system. In this example, Datum: ‘NAD 1983 2011 US Feet’ and Coordinate System: ‘StatePlane Illinois West FIPS 1202’. Export Q5_Events as new point feature class named Q5_pts. Use the IDW (Spatial Analyst) tool to interpolate a raster surface. Input point features: Q5_pts. Z value field: velocity Output raster: \\\\mvrdfs\\EGIS\\Work\\EMP\\HREP_Projects\\SteamboatSlough\\Mussels\\SteamboatMusselModel\\Adh\\Existing_condition\\existingcondition.gdb\\q5_velocity Complete these steps for the other variables, ‘depth’, ‘slope’, and ‘sheer stress’, ‘froude_number’, ‘reynolds_number’. 5.4 Convert to .bil format The goal of this step is to convert the Adh output into a format that can be used by Maxent. The .bil format is one of the formats common to both Maxent and Esri. This step will repeated for all Adh (Q5, Q95) predictors. Use the Copy Raster (Data Management) tool to covert the Adh predictor rasters into .bil format. Input Raster: q5_velocity Output Raster Dataset: \\\\mvrdfs\\egis\\Work\\EMP\\HREP_Projects\\SteamboatSlough\\Mussels\\SteamboatMusselModel\\Adh\\Existing_condition\\q5_velocity.bil (Note: cannot save .bil format within the .gdb) Format: Esri BIL 5.5 Calculate Slope The goal of the step is to calculate slope from the Adh depth variable created in the previous step. Use the Slope (Spatial Analyst) tool to calculate slope. Input raster: q5_depth Output raster: \\\\mvrdfs\\egis\\Work\\EMP\\HREP_Projects\\SteamboatSlough\\Mussels\\SteamboatMusselModel\\Adh\\Existing_condition\\existingcondition.gdb\\q5_slope Output measurement: degree Z factor = 1 (linear units same) Use Copy Raster (Data Management) tool to convert the q5_slope raster into .bil format, as outlined in previous step. "],
["prepare-wind-and-wave-data.html", "Chapter 6 Prepare Wind and Wave Data 6.1 Identify Appropriate Weather Stations 6.2 Obtain Wind Data 6.3 Determine Period of Record", " Chapter 6 Prepare Wind and Wave Data 6.1 Identify Appropriate Weather Stations 6.2 Obtain Wind Data 6.3 Determine Period of Record "],
["develop-maxent-mussel-model.html", "Chapter 7 Develop Maxent Mussel Model 7.1 Convert from .bil to .mxe format 7.2 Run Maxent 7.3 Convert model output from 7.4 Maxent speed Issues", " Chapter 7 Develop Maxent Mussel Model 7.1 Convert from .bil to .mxe format To speed model creation (from 10’s of hours to 10’s of minutes), convert the predictors to the Maxent .mxe format. Open command prompt and change directory by typing c: and then cd C:\\Users\\b6pdpdem\\Documents\\SteamboatMusselModel Create predictor_mxe folder java -Xmx5g -cp maxent.jar density.Convert C:\\Users\\b6pdpdem\\Documents\\SteamboatMusselModel\\predictors bil C:\\Users\\b6pdpdem\\Documents\\SteamboatMusselModel\\predictors_mxe mxe 7.2 Run Maxent 7.3 Convert model output from To convert the .mxe format back to a format that can be read by ESRI. java -Xmx5g -cp maxent.jar density.Convert C:\\Users\\b6pdpdem\\Documents\\SteamboatMusselModel\\sb_existing_20181203_2 mxe C:\\Users\\b6pdpdem\\Documents\\SteamboatMusselModel\\sb_existing_20181203_2 bil Use the Define Projection tool to set the projection of the .bil rasters. 7.4 Maxent speed Issues Follow these simple performance guidelines to reduce Maxent run time from a week to half an hour. Run the model on a physical computer, not on a virtual machine. Select a computer with the fastest processor and most memory available. Increase the memory available to the java virtual machine (JVM). Edit the first line of the maxent.bat file to something like the following: java -Xmx5g -jar maxent.jar, where the -Xmx parameter sets the maximum heap size for the JVM. Set it to something less than the total amount of physical memory on your computer. Do not run the model across the LAN (inputs and outputs stored on a network file system). Copy all inputs and write all outputs to the local file system. Use a solid state drive for storing inputs and outputs. Use the “SWD” format for specifying both samples (species occurances) and environmental layers (background points). Convert all predictor grids to the Maxent .mxe format. Write all outputs to the Maxent .mxe format. Set the threads parameter to at least the number of cores on your computer (or a large percentage of logical processors) to speed processing of replicates. "],
["model-interpretation.html", "Chapter 8 Model Interpretation 8.1 ?", " Chapter 8 Model Interpretation 8.1 ? "]
]
